############################################
#### Server
server:
  port: 8282



############################################
#### Spring
spring:
  #### Open Tracing
  zipkin:
    enabled: false

  #### Data Source
  datasource:
    driver-class-name: net.sf.log4jdbc.sql.jdbcapi.DriverSpy
    writer:
      jdbc-url: jdbc:log4jdbc:postgresql://bmt-vodprogramming-cluster.cluster-c2as9ee4bg3m.ap-northeast-2.rds.amazonaws.com:5432/mylgdb
      username: postgres
      password: BmtAdmin1!
      minimum-idle: 5
      maximum-pool-size: 5
    reader:
      jdbc-url: jdbc:log4jdbc:postgresql://bmt-vodprogramming-cluster.cluster-ro-c2as9ee4bg3m.ap-northeast-2.rds.amazonaws.com:5432/mylgdb
      username: postgres
      password: BmtAdmin1!
      minimum-idle: 5
      maximum-pool-size: 5

  #### JPA
  jpa:
    database: postgresql
    hibernate:
      use-new-id-generator-mappings: false
      naming:
        implicit-strategy: org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
    properties:
      hibernate:
        temp:
          use_jdbc_metadata_defaults: false
        format_sql: true
        jdbc:
          lob:
            non_contextual_creation: true

  ## Cache - Redis
  cache:
    type: redis
  redis:
    host: localhost
    port: 6379

  ## cloud stream
  cloud:
    stream:
      bindings:
        # inbound 채널, 메시지 수신 설정
        sample-in:
          # kafka는 topic, rabbitmq는 exchange
          destination: topic-sample
          content-type: application/json
          # fail-over & 중복 수신 방지
          # kafka topic으로 부터 consumer group 별로 하나의 메시지를 풀한다.
          group: group-sample
          consumer:
            max-attempts: 3
        # outbound 채널, 메시지 발송 설정
        # 보통 내부 MSA 서비스와 통신할 topic을 정의하기 때문에 송/수신용의 동일한 토픽을 사용할 일은 거의 없으나 테스트를 위해 발송 채널 정의
        sample-out:
          destination: topic-sample
          content-type: application/json
      # kafka, rabbitmq, aws sns/sqs 등의 설정, 메시지큐 변경 시 아래 부분만 수정하면 연동 및 비즈니스 로직은 수정할 필요가 없다.
      kafka:
        binder:
          brokers: localhost:9092
          # auto-create-topics: true
          auto-add-partitions: true
          configuration:
            retries: 5
        bindings:
          sample-in:
            # Dead Letter Processing, auto-bind-dlq는 dlq이름을 error.<topic>.<group>으로 생성
            consumer:
              enableDlq: true
              auto-bind-dlq: true



############################################
#### Logging
logging:
  level:
    com:
      lguplus:
        fleta: DEBUG
      zaxxer:
        hikari: DEBUG
    org:
#      hibernate:
#        SQL: DEBUG
#        type: TRACE
      springframework:
        cache: TRACE
        orm:
          jpa: DEBUG
        transaction:
          interceptor: TRACE
    jdbc:
      audit: OFF
      sqltiming: DEBUG
      resultsettable: DEBUG
      connection: DEBUG
      resultset: OFF
      sqlonly: OFF
  pattern:
    level: "%5p [${spring.application.name}][%X{saId:-}][%X{stbMac:-}]"



############################################
#### Other Domain Application Service
service:
  subscriber:
    base-url: http://subscriber.fleta.com
    enable: true
  vodlookup:
    url: http://vodlookup.fleta.com
  programming:
    url: http://programming.fleta.com



############################################
## FeignClient
feign:
  client:
    config:
      default:
        loggerLevel: FULL
